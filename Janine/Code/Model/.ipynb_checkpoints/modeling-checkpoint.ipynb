{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "stopwords_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import graphviz\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH'] + ';C:/Program Files (x86)/Graphviz2.38/bin'\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "datapath = '../../Data/Processed/intervencao_eqp.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:MediumSlateBlue\"> 1.Carga dos Dados </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (267318, 2)\n",
      "columns: Index(['CLASSE', 'TEXTO'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_parquet(datapath)\n",
    "\n",
    "print('shape:', dataframe.shape)\n",
    "print('columns:', dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:MediumSlateBlue\"> **2. Treino / Teste** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe['TEXTO'].values.reshape(-1).tolist()\n",
    "Y = (dataframe['CLASSE'].values.reshape(-1) == 'POS').tolist()\n",
    "\n",
    "# Dividir 20% dos dados para o conjunto out-of-sample de teste\n",
    "Xtrain, Xtest, Ytrain, Ytest = model_selection.train_test_split( X,\n",
    "                                                                 Y,\n",
    "                                                                 test_size=0.25,\n",
    "                                                                 random_state=0,\n",
    "                                                                 stratify=Y  )\n",
    "\n",
    "# Objeto de validacao cruzada\n",
    "cvfold = model_selection.StratifiedKFold(n_splits = 5, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:MediumSlateBlue\"> **3.Construção do Pipeline** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Configure Pipeline\n",
    "model_dict = {\n",
    "    'RandomForest': ensemble.RandomForestClassifier(n_estimators=10, max_features='sqrt'),\n",
    "    'LogisticRegr': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(weights='distance'),\n",
    "    'SVM': SVC(probability=False, gamma='auto'),\n",
    "}\n",
    "\n",
    "model_conf = {\n",
    "    'RandomForest': {\n",
    "        'Model__max_depth': [4, 6],\n",
    "        'Model__n_estimators': [10, 50],\n",
    "    },\n",
    "    'LogisticRegr': {\n",
    "        'Model__C': [0.001, 0.1, 1, 10],\n",
    "    },\n",
    "    'kNN': {\n",
    "        'Model__n_neighbors': [5, 10, 20],\n",
    "    },\n",
    "    'SVM': {\n",
    "        'Model__kernel': ['rbf',],\n",
    "        'Model__C' : [0.1, 1, 10],\n",
    "    }\n",
    "}\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "\n",
    "model_list = {}\n",
    "\n",
    "for model_name in model_dict.keys():\n",
    "    conf_train_pipe = [\n",
    "        ('TfIDf', TfidfVectorizer(Xtrain,stop_words=stopwords_nltk)),\n",
    "        ('Model', model_dict[model_name]),\n",
    "    ]\n",
    "    \n",
    "    #cross_val_score\n",
    "    # Create Pipeline\n",
    "    model_pipe = pipeline.Pipeline(conf_train_pipe)\n",
    "    param_grid = model_conf[model_name].copy()\n",
    "    model_pipe = model_selection.GridSearchCV(model_pipe, param_grid,\n",
    "                                              scoring=scorer,\n",
    "                                              #fit_params=None,\n",
    "                                              cv=cvfold,\n",
    "                                              return_train_score = True)\n",
    "    \n",
    "    \n",
    "\n",
    "    model_pipe.fit(Xtrain, Ytrain)\n",
    "    model_list[model_name] = model_pipe    \n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:MediumSlateBlue\"> **4. Curva ROC** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "for model_name in model_dict.keys():\n",
    "    model = model_list[model_name]\n",
    "    # estimate Y\n",
    "    if model_name in ['RandomForest', 'SVM']:\n",
    "        final_model = LogisticRegressionCV(Cs=20,cv=5)\n",
    "        if model_name == 'SVM':\n",
    "            Yhat_train = model.decision_function(Xtrain)\n",
    "            Yhat = model.decision_function(Xtest)\n",
    "        else:\n",
    "            Yhat_train = model.predict_proba(Xtrain)[:,1]\n",
    "            Yhat = model.predict_proba(Xtest)[:,1]\n",
    "            \n",
    "        final_model.fit(Yhat_train.reshape(-1, 1), Ytrain)\n",
    "        Yhat  = final_model.predict_proba(Yhat.reshape(-1,1))[:,1]\n",
    "        Ypred = final_model.predict(Yhat.reshape(-1,1))\n",
    "    else:\n",
    "        Yhat = model.predict_proba(Xtest)[:,1]\n",
    "        Ypred = model.predict(Xtest)\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thr = metrics.roc_curve(Ytest, Yhat)\n",
    "    auc = metrics.roc_auc_score(Ytest, Yhat)\n",
    "    f1 = metrics.f1_score(Ytest, Ypred)\n",
    "    label = model_name # + \" AUC: %.3f - F1: %.3f\"%(auc, f1)\n",
    "    plt.plot(fpr, tpr, '-', lw=2, label=label)\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Classificador Vinhos de Alta Qualidade')\n",
    "plt.grid()\n",
    "plt.xlabel('Taxa de Falso Alarme')\n",
    "plt.ylabel('Taxa de Detecção')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição de Probabilidades do Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LogisticRegr'\n",
    "model = model_list[model_name]\n",
    "Yhat = model.predict_proba(Xtest)[:,1]\n",
    "\n",
    "for i in [False, True]:\n",
    "    # 2 Classes case\n",
    "    sns.distplot(Yhat[np.array(Ytest) == i], label=['NEG','POS'][i])\n",
    "\n",
    "plt.title(model_name)\n",
    "plt.ylabel('Densidade Estimada KDE')\n",
    "plt.xlabel('Probabilidade Sentimento Positivo')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de Confusão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LogisticRegr'\n",
    "\n",
    "\n",
    "model = model_list[model_name]\n",
    "Ypred = model.predict(Xtest)\n",
    "\n",
    "col_names = ['Model ' + s for s in ['Neg','Pos']]\n",
    "idx_names = ['Real ' + s for s in ['Neg','Pos']]\n",
    "\n",
    "cmat = metrics.confusion_matrix(Ytest, Ypred)\n",
    "cmat = pandas.DataFrame(cmat, index=idx_names,\n",
    "                              columns=col_names)\n",
    "cmat['Real Total'] = cmat.sum(axis=1)\n",
    "cmat.loc['Model Total',:] = cmat.sum(axis=0)\n",
    "cmat = cmat.astype(int)\n",
    "cmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(Ytest, Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coeficientes de Regressão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "nshow = 10\n",
    "model_name = 'LogisticRegr'\n",
    "model = model_list[model_name].best_estimator_.steps[1][1]\n",
    "vocabulary = model_list[model_name].best_estimator_.steps[0][1].vocabulary_\n",
    "vocabulary = np.array(list(vocabulary.keys()))\n",
    "\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "idx = np.argsort(np.abs(coefs))[-nshow:]\n",
    "\n",
    "yaxis = np.arange(nshow)\n",
    "\n",
    "\n",
    "plt.barh(yaxis, coefs[idx])\n",
    "plt.yticks(yaxis, vocabulary[idx])\n",
    "\n",
    "plt.title('Coeficientes da Regressão')\n",
    "plt.xlabel('Coeficiente')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicação pela Árvore de Decisão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "nshow = 10\n",
    "model_name = 'RandomForest'\n",
    "model = model_list[model_name].best_estimator_.steps[1][1]\n",
    "vocabulary = model_list[model_name].best_estimator_.steps[0][1].vocabulary_\n",
    "vocabulary = np.array(list(vocabulary.keys()))\n",
    "\n",
    "coefs = model.feature_importances_\n",
    "\n",
    "idx = np.argsort(np.abs(coefs))[-nshow:]\n",
    "\n",
    "yaxis = np.arange(nshow)\n",
    "\n",
    "\n",
    "plt.barh(yaxis, coefs[idx])\n",
    "plt.yticks(yaxis, vocabulary[idx])\n",
    "\n",
    "plt.title(model_name + '  - Importância Features')\n",
    "\n",
    "plt.xlabel('Importância Relativa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportação do Resultado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LogisticRegr'\n",
    "\n",
    "test_data = [Xtest, Ytest,]\n",
    "df_cols = ['text', 'class'] \n",
    "for model_name in model_dict.keys():\n",
    "    model = model_list[model_name]\n",
    "    if model_name in ['RandomForest', 'SVM']:\n",
    "        final_model = LogisticRegressionCV(Cs=20,cv=5)\n",
    "        if model_name == 'SVM':\n",
    "            Yhat_train = model.decision_function(Xtrain)\n",
    "            Yhat = model.decision_function(Xtest)\n",
    "        else:\n",
    "            Yhat_train = model.predict_proba(Xtrain)[:,1]\n",
    "            Yhat = model.predict_proba(Xtest)[:,1]\n",
    "            \n",
    "        final_model.fit(Yhat_train.reshape(-1, 1), Ytrain)\n",
    "        Yhat  = final_model.predict_proba(Yhat.reshape(-1,1))[:,1]\n",
    "    else:\n",
    "        Yhat = model.predict_proba(Xtest)[:,1]\n",
    "\n",
    "    test_data.append(Yhat)\n",
    "    df_cols.append(model_name)\n",
    "        \n",
    "test_data = np.array(test_data).T\n",
    "df_test = pd.DataFrame(data=test_data, columns=df_cols)\n",
    "\n",
    "df_test.to_excel('../../Data/Modeling/results.xlsx')\n",
    "\n",
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
